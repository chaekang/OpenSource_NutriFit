import streamlit as st
import pandas as pd
import numpy as np
import torch
from sentence_transformers import SentenceTransformer, util
from PIL import Image
import requests
import io
import json
import base64
import global_list
from dotenv import load_dotenv
import os
import openai

# Load environment variables
load_dotenv()

# Load model
model_name = 'jhgan/ko-sroberta-multitask'
model = SentenceTransformer(model_name)

# Load the filtered DataFrame
LAST_DF_PATH = 'compact_kosroberta_recipes.pkl'
df = pd.read_pickle(LAST_DF_PATH)
df = df.reset_index(drop=True)

openai.api_key = os.getenv('OPENAI_API_KEY')

# Initialize Streamlit
st.set_page_config(page_title="NutriFit", page_icon=":cook:", layout="wide")

# Initialize 'senior_mode' in session state
if 'senior_mode' not in st.session_state:
    st.session_state['senior_mode'] = False

# Define the msg_prompt dictionary
msg_prompt = {
    'recom': {
        'system': "You are a helpful assistant who recommend food items based on user question.",
        'user': "Write 1 sentence of a very simple greeting that starts with 'ì¶”ì²œë“œë¦¬ê² ìŠµë‹ˆë‹¤!' to recommend food items to users. and don't say any food name, say in korean",
    },
    'desc': {
        'system': "You are an assistant who very simply answers.",
        'user': "Please write a simple greeting starting with 'ìš”ë¦¬ì— ëŒ€í•´ ì„¤ëª…í• ê²Œìš”' to explain the recipes to the user.",
    },
    'how': {
        'system': "You are a helpful assistant who kindly answers.",
        'user': "Please write a simple greeting starting with 'ë°©ë²•ì„ ë§ì”€ë“œë¦´ê²Œìš”' to explain the recipes to the user.",
    },
    'intent': {
        'system': "You are a helpful assistant who understands the intent of the user's query. and You answer in a short answer",
        'user': "Which category does the sentence below belong to: 'recommendation', 'description', how to cook'? pick one category. \n context:"
    }
}

## OpenAI APIì™€ GPT-3 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ msgì— ëŒ€í•œ ì‘ë‹µ ìƒì„±
# ì´ì „ ëŒ€í™”ë‚´ìš©ì„ ê³ ë ¤í•˜ì—¬ ëŒ€í™” ìƒì„±.
def get_chatgpt_msg(msg):
    completion = openai.ChatCompletion.create(
                    model='gpt-3.5-turbo',
                    messages=msg
                    )
    return completion['choices'][0]['message']['content']

def toggle_senior_mode():
    st.session_state['senior_mode'] = not st.session_state['senior_mode']

st.button('ì‹œë‹ˆì–´ ëª¨ë“œ ì¼œê¸°' if not st.session_state['senior_mode'] else 'ì‹œë‹ˆì–´ ëª¨ë“œ ë„ê¸°', on_click=toggle_senior_mode)

if st.session_state['senior_mode']:
    st.markdown("""
        <style>
        body, h1, h2, h3, h4, h5, h6, p, span, div, input, button {
            font-size: 40px !important;
        }
        </style>
    """, unsafe_allow_html=True)

# Main content
st.markdown("<span style='color:lightgray; font-style:italic; font-size:12px;'>24-1 ì˜¤í”ˆì†ŒìŠ¤í”„ë¡œê·¸ë˜ë° ê¸°ë§ í”„ë¡œì íŠ¸ íŒ€ NutriFit' </span>", unsafe_allow_html=True)
curr_dir = os.getcwd()
img_path = os.path.join(curr_dir, "NutriFit.jpg")
image = Image.open(img_path)
st.image(image)
img_path = os.path.join(curr_dir, "chatê°•ë¡2-2.jpg")
image2 = Image.open(img_path)
st.image(image2)

st.write('\n')
st.write('\n\n')

chat_history = st.session_state.get("chat_history", [])

## intentì™€ ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ prompt ìƒì„±
# ì ì ˆí•œ ì´ˆê¸° ë©”ì„¸ì§€ ìƒì„±, ì‚¬ìš©ìì™€ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”êµ¬ì„± ê°€ëŠ¥.
def set_prompt(intent, query, msg_prompt_init, model):
    '''prompt í˜•íƒœë¥¼ ë§Œë“¤ì–´ì£¼ëŠ” í•¨ìˆ˜'''
    m = dict()
    # ì¶”ì²œì¼ ê²½ìš°
    if 'recom' in intent:
        msg = msg_prompt_init['recom']  # ì‹œìŠ¤í…œ ë©”ì„¸ì§€ë¥¼ ê°€ì ¸ì˜´
    # ì„¤ëª…ì¼ ê²½ìš°
    elif 'desc' in intent:
        msg = msg_prompt_init['desc']  # ì‹œìŠ¤í…œ ë©”ì„¸ì§€ë¥¼ ê°€ì ¸ì˜´
    # ìš”ë¦¬ë°©ë²•ì¼ ê²½ìš°
    elif 'how' in intent:
        msg = msg_prompt_init['how']  # ì‹œìŠ¤í…œ ë©”ì„¸ì§€ë¥¼ ê°€ì ¸ì˜´
    # intent íŒŒì•…
    else:
        msg = msg_prompt_init['intent']
        msg['user'] += f' {query} \n A:'
    for k, v in msg.items():
        m['role'], m['content'] = k, v
    return [m]

## ìƒìœ„ 5ê°œ í•­ëª© ì¶œë ¥(ë§í¬ë¡œ ì¤‘ë³µì œê±°-ë¯¼ê·œë‹˜)
def get_query_sim_top_k(query, model, df):
    "ì¿¼ë¦¬ì™€ ë°ì´í„° ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•˜ê³  ìœ ì‚¬í•œ ìˆœìœ„ 5ê°œ ë°˜í™˜"
    if df['ko-sroberta-multitask-feature'].isnull().all():
        raise ValueError("DataFrameì˜ 'ko-sroberta-multitask-feature' ì—´ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
    
    query_encode = model.encode(query)
    cos_scores = util.pytorch_cos_sim(query_encode, df['ko-sroberta-multitask-feature'])[0]
    
    if cos_scores.size(0) == 0:
        raise ValueError("ìœ ì‚¬í•œ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¿¼ë¦¬ë¥¼ ì‹œë„í•´ ì£¼ì„¸ìš”.")
    
    top_results = torch.topk(cos_scores, k=1)
    return top_results

# ì±—ë´‡ ìƒì„±í•˜ê¸°
if 'generated' not in st.session_state:
    st.session_state['generated'] = []

if 'past' not in st.session_state:
    st.session_state['past'] = []

query = None
with st.form(key='my_form'):
    query = st.text_input('ì…ë ¥ì°½ â†“')
    submitted = st.form_submit_button('ì§ˆë¬¸í•˜ê¸°')

def user_interact(query, model, msg_prompt_init):
    global global_list
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ ê¸°ë¡ì´ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    if not hasattr(global_list, 'user_msg_history'):
        global_list.user_msg_history = []

    user_intent = set_prompt('intent', query, msg_prompt_init, None)
    user_intent = get_chatgpt_msg(user_intent).lower()
    print("user_intent : ", user_intent)
    
    intent_data = set_prompt(user_intent, query, msg_prompt_init, model)
    intent_data_msg = get_chatgpt_msg(intent_data).replace("\n", "").strip()
    print("intent_data_msg : ", intent_data_msg)
    
    try:
        if ('recom' in user_intent):
            global_list.user_msg_history = []
            recom_msg = str()
            
            top_result = get_query_sim_top_k(query, model, df)
            top_index = top_result[1].numpy() if 'recom' in user_intent else top_result[1].numpy()[1:]
            r_set_d = df.iloc[top_index, :][['ìš”ë¦¬', 'ì¢…ë¥˜', 'ì¬ë£Œ', 'ì‚¬ì§„', 'ìš”ë¦¬ë°©ë²•']]
            r_set_d = json.loads(r_set_d.to_json(orient="records"))
            for r in r_set_d:
                for _, v in r.items():
                    recom_msg += f"{v} \n"
                    img_url = r['ì‚¬ì§„']
                    response = requests.get(img_url)
                    image_bytes = io.BytesIO(response.content)
                    image = Image.open(image_bytes)
                    img_md = f"<img src='data:image/png;base64,{base64.b64encode(image_bytes.getvalue()).decode()}' style='padding-left: 70px; width:550px;'/>"

                    r_ingredients = r['ì¬ë£Œ'].split()
                    button_html = ''
                    for ing in r_ingredients:
                        gs_url = f"https://m.gsfresh.com/shop/search/searchSect.gs?tq={ing}&mseq=S-11209-0301&keyword={ing}"
                        button_html += f"""<span style="white-space: nowrap;"><a href="{gs_url}" target="_blank" style="text-decoration: none; color: white; background-color: #008A7B; padding: 6px 12px; border-radius: 5px; margin-right: 5px; margin-bottom: 5px; margin-top: 5px;">{ing}</a></span>"""
                    
                    def recipe():
                        recipe_str = ''
                        for i, step in enumerate(recipe_steps):
                            step = step.strip()  
                            if step:  
                                recipe_str += f"{i+1}. {step}\n\n"
                        return recipe_str
                    recipe_steps = r['ìš”ë¦¬ë°©ë²•'].replace('[', '').replace(']', '').replace("\\xa0", " ").replace("\\r\\n", ' ').split("', ")
                    recipe_steps = [step.split("\\n") for step in recipe_steps]
                    recipe_steps = [step for sublist in recipe_steps for step in sublist]
                    recipe_steps = [step.strip() for step in recipe_steps]
                    recipe_steps = [step.replace("'", "") for step in recipe_steps]
                    
                recom_msg = f"ì¶”ì²œë©”ë‰´ \" {r['ìš”ë¦¬']} \" ({r['ì¢…ë¥˜']})"
                recipe_msg = ""
                recipe_msg += f"\"{r['ìš”ë¦¬']}\" ë ˆì‹œí”¼ë¥¼ ì•Œë ¤ë“œë¦´ê²Œìš”. \n\n "
                recipe_msg += recipe()
            global_list.user_msg_history.append({'role' : 'assistant', 'content' : [query, f"{intent_data_msg} {str(recom_msg)}"]})
            return recom_msg, img_md, f"{intent_data_msg}", button_html, recipe_msg, img_url
        
        elif 'desc' in user_intent:
            if not global_list.user_msg_history:
                raise ValueError("No previous user query available for description.")
            top_result = get_query_sim_top_k(global_list.user_msg_history[0]['content'][0], model, df)
            r_set_n = df.loc[top_result[1].numpy(), 'ìš”ë¦¬']
            r_set_d = df.iloc[top_result[1].numpy(), :]['ì„¤ëª…']
            r_set_d = json.loads(r_set_d.to_json(orient="records"))[0]
            global_list.user_msg_history.append({'role' : 'assistant', 'content' : r_set_d})
            return f' "{r_set_n.iloc[-1]}" ì†Œê°œë¥¼ í•´ë“œë¦´ê²Œìš”! \n\n {r_set_d}'
        
        elif 'how' in user_intent:
            if not global_list.user_msg_history:
                raise ValueError("No previous user query available for cooking instructions.")
            top_result = get_query_sim_top_k(global_list.user_msg_history[0]['content'][0], model, df)
            r_set_d = df.iloc[top_result[1].numpy(), :]['ìš”ë¦¬ë°©ë²•']
            r_set_n = df.iloc[top_result[1].numpy(), :]['ìš”ë¦¬'].values[0]
            
            r_set_d_list = []
            for s in r_set_d:
                s_list = s.split("', ")
                for i in range(len(s_list)):
                    s_list[i] = s_list[i].replace("'", "").replace(",", "").replace('[','').replace(']','').replace('\\xa0', ' ').replace('\\r\\n', '')
                r_set_d_list.extend(s_list)
                
            re_num = ""
            for i, s in enumerate(r_set_d_list, 1):
                re_num += f"{i}. {s} \n"
            global_list.user_msg_history.append({'role' : 'assistant', 'content' : r_set_d_list})

            return f'"{r_set_n}" ìš”ë¦¬ë°©ë²•ì„ ì•Œë ¤ë“œë¦´ê²Œìš”! \n\n {re_num}'
    
    except ValueError as e:
        return str(e)

if __name__ == "__main__":
   
    chat_history = st.session_state.get("chat_history", [])
    
    if 'generated' not in st.session_state:
        st.session_state['generated'] = []

    if 'past' not in st.session_state:
        st.session_state['past'] = []

    if submitted and query:
        output = user_interact(query, model, msg_prompt)
        chat_history.append(query)
        st.session_state.past.append(query)
        st.session_state.past.append(output)
        
        if isinstance(output, tuple):
            st.markdown(f"<div style='padding-left: 70px;'> <h5> ğŸ³ {output[0]} </h5> </div>", unsafe_allow_html=True)
            st.markdown(output[1], unsafe_allow_html=True)
            st.markdown(output[2], unsafe_allow_html=True)
            st.markdown(output[4], unsafe_allow_html=True)
            st.markdown(f"<p style='padding-left: 70px; padding-right: 120px; font-size:16px; font-weight:bold; font-style:italic;'> (ì¬ë£Œë¥¼ ëˆ„ë¥´ì‹œë©´ êµ¬ë§¤í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.) <br> <span class='no-style'>{output[3]}</span> </p>", unsafe_allow_html=True)
            chat_history.append(output)
        else:
            st.write(output)
            chat_history.append(output)
        
        st.session_state["chat_history"] = chat_history
    
    if len(chat_history) > 2:
        for i in range(len(chat_history)-3, -1, -1):
            if i % 2 == 0:
                st.write(chat_history[i]) 
            else:
                if isinstance(chat_history[i], tuple):
                    st.markdown(f"<div style='padding-left: 70px;'> <h5> ğŸ³ {chat_history[i][0]} </h5> </div>", unsafe_allow_html=True)
                    st.markdown(chat_history[i][1], unsafe_allow_html=True)
                    st.markdown(chat_history[i][2], unsafe_allow_html=True)
                    st.markdown(chat_history[i][4], unsafe_allow_html=True)
                    st.markdown(f"<p style='padding-left: 70px; padding-right: 120px; font-size:16px; font-weight:bold; font-style:italic;'> (ì¬ë£Œë¥¼ ëˆ„ë¥´ì‹œë©´ êµ¬ë§¤í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.) <br> <span class='no-style'>{chat_history[i][3]}</span> </p>", unsafe_allow_html=True)
                else:
                    st.write(chat_history[i])
